{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use instance ml.m5.large for SentenceTransformers\n",
    "!pip install -U sentence-transformers\n",
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import reduce\n",
    "# from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import silhouette_score\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "%matplotlib inline \n",
    "pio.renderers.default='iframe'\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    file_path = \"Top 25 skills for Sub Analysis (By Year and ONET | with NAICS filter).xlsx\"\n",
    "    new_columns = ['onet_parent','onet_child']\n",
    "    df_1 = pd.read_excel(file_path, sheet_name='2010')\n",
    "    df_1[new_columns] = df_1['onet'].str.split('-', 1, expand=True)\n",
    "    df_2 = pd.read_excel(file_path, sheet_name='2011')\n",
    "    df_2[new_columns] = df_2['onet'].str.split('-', 1, expand=True)\n",
    "    df_3 = pd.read_excel(file_path, sheet_name='2012')\n",
    "    df_3[new_columns] = df_3['onet'].str.split('-', 1, expand=True)\n",
    "    df_4 = pd.read_excel(file_path, sheet_name='2013')\n",
    "    df_4[new_columns] = df_4['onet'].str.split('-', 1, expand=True)\n",
    "    df_5 = pd.read_excel(file_path, sheet_name='2014')\n",
    "    df_5[new_columns] = df_5['onet'].str.split('-', 1, expand=True)\n",
    "    df_6 = pd.read_excel(file_path, sheet_name='2015')\n",
    "    df_6[new_columns] = df_6['onet'].str.split('-', 1, expand=True)\n",
    "    df_7 = pd.read_excel(file_path, sheet_name='2016')\n",
    "    df_7[new_columns] = df_7['onet'].str.split('-', 1, expand=True)\n",
    "    df_8 = pd.read_excel(file_path, sheet_name='2017')\n",
    "    df_8[new_columns] = df_8['onet'].str.split('-', 1, expand=True)\n",
    "    df_9 = pd.read_excel(file_path, sheet_name='2018')\n",
    "    df_9[new_columns] = df_9['onet'].str.split('-', 1, expand=True)\n",
    "    df_10 = pd.read_excel(file_path, sheet_name='2019')\n",
    "    df_10[new_columns] = df_10['onet'].str.split('-', 1, expand=True)\n",
    "    df_11 = pd.read_excel(file_path, sheet_name='2020')\n",
    "    df_11[new_columns] = df_11['onet'].str.split('-', 1, expand=True)\n",
    "    df_12 = pd.read_excel(file_path, sheet_name='2021')\n",
    "    df_12[new_columns] = df_12['onet'].str.split('-', 1, expand=True)\n",
    "    return df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020, df_2021 = setup()\n",
    "dfs = [df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020, df_2021]\n",
    "\n",
    "years = list(range(2010, 2022))\n",
    "yearly_dfs = {2010: df_2010, 2011: df_2011, 2012: df_2012, 2013: df_2013, 2014: df_2014, 2015: df_2015, \n",
    "              2016: df_2016, 2017: df_2017, 2018: df_2018, 2019: df_2019, 2020: df_2020, 2021: df_2021}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONET Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf 'Sub Analysis'\n",
    "!mkdir 'Sub Analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(2,30)\n",
    "parent_folder = 'Sub Analysis'\n",
    "title = 'Sub Analysis for the News Media ONET Codes'\n",
    "onet_model = parent_folder+'/model.pkl'\n",
    "# language_model = 'all-MiniLM-L6-v2'\n",
    "language_model = 'all-mpnet-base-v2'\n",
    "onet_k_value = parent_folder+'/k_value.png'\n",
    "onet_cluster_data = parent_folder+'/cluster_data'\n",
    "onet_bar_chart = parent_folder+'/bar_charts.html'\n",
    "onet_line_chart = parent_folder+'/line_chart.html'\n",
    "onet_bubble_chart = parent_folder+'/bubble_chart.html'\n",
    "normalized_onet_cluster_data = parent_folder+'/normalized_cluster_data'\n",
    "normalized_onet_bar_chart = parent_folder+'/normalized_bar_charts.html'\n",
    "normalized_onet_line_chart = parent_folder+'/normalized_line_chart.html'\n",
    "normalized_onet_bubble_chart = parent_folder+'/normalized_bubble_chart.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of skills\n",
    "skills = []\n",
    "skills_per_year = []\n",
    "for df in dfs:\n",
    "    skills.extend(df['skill'].unique().tolist())\n",
    "    skills_per_year.append(df['skill'].unique().tolist())\n",
    "skills = list(set(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Embeddings\n",
    "model = SentenceTransformer(language_model)\n",
    "skills_embeddings = model.encode(skills)\n",
    "skills_per_year_embeddings = []\n",
    "for item in skills_per_year:\n",
    "    skills_per_year_embeddings.append(model.encode(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal K value based on silhouette score is 26 with a score of 0.049083661288022995\n"
     ]
    }
   ],
   "source": [
    "# using elbow method to figure out ideal number of clusters\n",
    "# distortions = []\n",
    "score=0\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, init='k-means++')\n",
    "    model.fit_predict(skills_embeddings)\n",
    "#     distortions.append(model.inertia_)\n",
    "    new_score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "    if new_score>score:\n",
    "        number_of_clusters = k\n",
    "        score=new_score\n",
    "\n",
    "print(\"Ideal K value based on silhouette score is {} with a score of {}\".format(number_of_clusters, score))\n",
    "# kn = KneeLocator(list(K), distortions, S=1.0, curve='convex', direction='decreasing')\n",
    "# number_of_clusters = kn.knee\n",
    "# print(\"Ideal K value based on elbow method = {}\".format(number_of_clusters))\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.vlines(number_of_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.savefig(onet_k_value, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.048\n"
     ]
    }
   ],
   "source": [
    "model = KMeans(n_clusters=number_of_clusters)\n",
    "cluster_assignment = model.fit_predict(skills_embeddings)\n",
    "\n",
    "clustered_skills = {}\n",
    "for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_skills:\n",
    "        clustered_skills[cluster_id] = []\n",
    "    clustered_skills[cluster_id].append(skills[skill_id])\n",
    "\n",
    "score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "print('Silhouette Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = \"{'silhouette_score':'\"+str(score)+\"',\"\n",
    "for key in sorted(clustered_skills):\n",
    "    cluster_data=cluster_data+str(key)+\":\"+str(clustered_skills[key])+\",\"\n",
    "cluster_data=cluster_data[:-1]+\"}\"\n",
    "with open(onet_cluster_data+\".json\", 'w') as f:\n",
    "    f.write(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(onet_model, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(onet_model, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for year 2010\n",
      "Predicting for year 2011\n",
      "Predicting for year 2012\n",
      "Predicting for year 2013\n",
      "Predicting for year 2014\n",
      "Predicting for year 2015\n",
      "Predicting for year 2016\n",
      "Predicting for year 2017\n",
      "Predicting for year 2018\n",
      "Predicting for year 2019\n",
      "Predicting for year 2020\n",
      "Predicting for year 2021\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['year', 'skills', 'cluster', \n",
    "                           'cluster_centers', 'cluster_centers_x', 'cluster_centers_y', \n",
    "                           'cluster_skill_count'], dtype=object)\n",
    "\n",
    "for i in range(0, len(skills_per_year_embeddings)):\n",
    "    year=years[i]\n",
    "    print(\"Predicting for year {}\".format(year))\n",
    "    cluster_assignment = model.predict(skills_per_year_embeddings[i])\n",
    "\n",
    "    clustered_skills = {}\n",
    "    for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "        if cluster_id not in clustered_skills:\n",
    "            clustered_skills[cluster_id] = []\n",
    "        clustered_skills[cluster_id].append(skills_per_year[i][skill_id])\n",
    "    \n",
    "    for key in sorted(clustered_skills):\n",
    "        count = 0\n",
    "        for skill in clustered_skills[key]:\n",
    "            count += yearly_dfs[year].loc[yearly_dfs[year]['skill'] == skill, 'count'].sum()\n",
    "        row = {'year': year, 'skills':', '.join(clustered_skills[key]), 'cluster':key, \n",
    "               'cluster_centers': key+1,'cluster_centers_x': model.cluster_centers_[:,0],\n",
    "               'cluster_centers_y': model.cluster_centers_[:,1], 'cluster_skill_count':count}\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "df.year = df.year.astype(int)\n",
    "df.cluster = df.cluster.astype(int)\n",
    "df.cluster_skill_count = df.cluster_skill_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='cluster_skill_count',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\"},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='cluster_skill_count', title='2010', labels=labels),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='cluster_skill_count', title='2011', labels=labels),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='cluster_skill_count', title='2012', labels=labels),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='cluster_skill_count', title='2013', labels=labels),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='cluster_skill_count', title='2014', labels=labels),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='cluster_skill_count', title='2015', labels=labels),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='cluster_skill_count', title='2016', labels=labels),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='cluster_skill_count', title='2017', labels=labels),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='cluster_skill_count', title='2018', labels=labels),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='cluster_skill_count', title='2019', labels=labels),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='cluster_skill_count', title='2020', labels=labels),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='cluster_skill_count', title='2021', labels=labels)\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "\n",
    "fig = px.line(df, x='year', y='cluster_skill_count', color='cluster', labels=labels)\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(onet_line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Now that we are done with a basic comparison, let us normalize the data and try to visualize it.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>skills</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_centers</th>\n",
       "      <th>cluster_centers_x</th>\n",
       "      <th>cluster_centers_y</th>\n",
       "      <th>cluster_skill_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Mainstreaming, Self-Starter, Sociology</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 0.00337401  0.03282966  0.0326455   0.006920...</td>\n",
       "      <td>[ 0.03909327 -0.01626172  0.00322638 -0.030199...</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                                  skills  cluster  cluster_centers  \\\n",
       "0  2010  Mainstreaming, Self-Starter, Sociology        0                1   \n",
       "\n",
       "                                   cluster_centers_x  \\\n",
       "0  [ 0.00337401  0.03282966  0.0326455   0.006920...   \n",
       "\n",
       "                                   cluster_centers_y  cluster_skill_count  \n",
       "0  [ 0.03909327 -0.01626172  0.00322638 -0.030199...                  412  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "clusters = df['cluster'].unique().tolist()\n",
    "for cluster in clusters:\n",
    "    temp_df = df[df['cluster']==cluster]\n",
    "    min_val = temp_df['cluster_skill_count'].min()\n",
    "    max_val = temp_df['cluster_skill_count'].max()\n",
    "    temp_df['normalized_score'] = (temp_df['cluster_skill_count'] - min_val)/(max_val-min_val)\n",
    "    new_df = pd.concat([new_df,temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(normalized_onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(normalized_onet_cluster_data+\".csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='normalized_score',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True, 'normalized_score': True, 'cluster_skill_count': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\", 'normalized_score': 'Normalized Score'},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(normalized_onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='normalized_score', title='2010', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='normalized_score', title='2011', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='normalized_score', title='2012', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='normalized_score', title='2013', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='normalized_score', title='2014', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='normalized_score', title='2015', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='normalized_score', title='2016', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='normalized_score', title='2017', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='normalized_score', title='2018', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='normalized_score', title='2019', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='normalized_score', title='2020', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    ),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='normalized_score', title='2021', custom_data=['cluster_skill_count'])\n",
    "    .update_traces(\n",
    "        hovertemplate=\"<br>\".join([\n",
    "            \"Cluster: %{x}\",\n",
    "            \"Count: %{customdata[0]}\",\n",
    "            \"Normalized Score: %{y}\"\n",
    "        ])\n",
    "    )\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(normalized_onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df, x='year', y='normalized_score', color='cluster', custom_data=['cluster_skill_count', 'cluster'])\n",
    "fig.update_traces(\n",
    "    hovertemplate=\"<br>\".join([\n",
    "        \"Cluster: %{customdata[1]}\",\n",
    "        \"Year: %{x}\",\n",
    "        \"Normalized Score: %{y}\",\n",
    "        \"Count: %{customdata[0]}\",\n",
    "    ])\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(normalized_onet_line_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
