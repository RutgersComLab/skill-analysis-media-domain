{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "## use instance ml.m5.large for SentenceTransformers\n",
    "!pip install -U sentence-transformers\n",
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import reduce\n",
    "# from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "%matplotlib inline \n",
    "pio.renderers.default='iframe'\n",
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup():\n",
    "    file_path = \"Top 50 skills (By Year and ONET _ with NAICS filter).xlsx\"\n",
    "    new_columns = ['onet_parent','onet_child']\n",
    "    df_1 = pd.read_excel(file_path, sheet_name='2010')\n",
    "    df_1[new_columns] = df_1['onet'].str.split('-', 1, expand=True)\n",
    "    df_2 = pd.read_excel(file_path, sheet_name='2011')\n",
    "    df_2[new_columns] = df_2['onet'].str.split('-', 1, expand=True)\n",
    "    df_3 = pd.read_excel(file_path, sheet_name='2012')\n",
    "    df_3[new_columns] = df_3['onet'].str.split('-', 1, expand=True)\n",
    "    df_4 = pd.read_excel(file_path, sheet_name='2013')\n",
    "    df_4[new_columns] = df_4['onet'].str.split('-', 1, expand=True)\n",
    "    df_5 = pd.read_excel(file_path, sheet_name='2014')\n",
    "    df_5[new_columns] = df_5['onet'].str.split('-', 1, expand=True)\n",
    "    df_6 = pd.read_excel(file_path, sheet_name='2015')\n",
    "    df_6[new_columns] = df_6['onet'].str.split('-', 1, expand=True)\n",
    "    df_7 = pd.read_excel(file_path, sheet_name='2016')\n",
    "    df_7[new_columns] = df_7['onet'].str.split('-', 1, expand=True)\n",
    "    df_8 = pd.read_excel(file_path, sheet_name='2017')\n",
    "    df_8[new_columns] = df_8['onet'].str.split('-', 1, expand=True)\n",
    "    df_9 = pd.read_excel(file_path, sheet_name='2018')\n",
    "    df_9[new_columns] = df_9['onet'].str.split('-', 1, expand=True)\n",
    "    df_10 = pd.read_excel(file_path, sheet_name='2019')\n",
    "    df_10[new_columns] = df_10['onet'].str.split('-', 1, expand=True)\n",
    "    df_11 = pd.read_excel(file_path, sheet_name='2020')\n",
    "    df_11[new_columns] = df_11['onet'].str.split('-', 1, expand=True)\n",
    "    df_12 = pd.read_excel(file_path, sheet_name='2021')\n",
    "    df_12[new_columns] = df_12['onet'].str.split('-', 1, expand=True)\n",
    "    return df_1, df_2, df_3, df_4, df_5, df_6, df_7, df_8, df_9, df_10, df_11, df_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_intersection() -> list:\n",
    "    return (list((reduce(np.intersect1d,\n",
    "                         [df_2010['onet'], df_2011['onet'], df_2012['onet'], df_2013['onet'], df_2014['onet'],\n",
    "                          df_2015['onet'], df_2016['onet'], df_2017['onet'], df_2018['onet'], df_2019['onet'],\n",
    "                          df_2020['onet'], df_2021['onet']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_union() -> list:\n",
    "    return (list((reduce(np.union1d,\n",
    "                         [df_2010['onet'], df_2011['onet'], df_2012['onet'], df_2013['onet'], df_2014['onet'],\n",
    "                          df_2015['onet'], df_2016['onet'], df_2017['onet'], df_2018['onet'], df_2019['onet'],\n",
    "                          df_2020['onet'], df_2021['onet']]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020, df_2021 = setup()\n",
    "dfs = [df_2010, df_2011, df_2012, df_2013, df_2014, df_2015, df_2016, df_2017, df_2018, df_2019, df_2020, df_2021]\n",
    "\n",
    "years = list(range(2010, 2022))\n",
    "yearly_dfs = {2010: df_2010, 2011: df_2011, 2012: df_2012, 2013: df_2013, 2014: df_2014, 2015: df_2015, \n",
    "              2016: df_2016, 2017: df_2017, 2018: df_2018, 2019: df_2019, 2020: df_2020, 2021: df_2021}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of ONET codes: 155\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of ONET codes: {}\".format(len(find_union())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ONET codes available in all years: 99\n",
      "['13-1022.00', '13-1023.00', '13-1031.01', '13-1041.07', '13-1051.00', '13-1071.00', '13-1081.00', '13-1081.02', '13-1111.00', '13-1121.00', '13-1141.00', '13-1151.00', '13-1161.00', '13-1199.00', '13-1199.01', '13-1199.02', '13-1199.04', '13-1199.06', '13-2011.01', '13-2011.02', '13-2041.00', '13-2051.00', '13-2052.00', '13-2053.00', '13-2071.00', '13-2072.00', '13-2081.00', '13-2099.01', '13-2099.02', '13-2099.03', '13-2099.04', '15-1111.00', '15-1121.00', '15-1122.00', '15-1131.00', '15-1132.00', '15-1133.00', '15-1134.00', '15-1141.00', '15-1142.00', '15-1143.00', '15-1143.01', '15-1151.00', '15-1152.00', '15-1199.00', '15-1199.01', '15-1199.02', '15-1199.03', '15-1199.04', '15-1199.06', '15-1199.07', '15-1199.08', '15-1199.09', '15-1199.10', '15-1199.11', '15-1199.12', '15-2031.00', '15-2041.00', '15-2041.01', '27-1011.00', '27-1013.00', '27-1014.00', '27-1021.00', '27-1022.00', '27-1024.00', '27-1025.00', '27-1026.00', '27-1029.00', '27-2012.01', '27-2012.03', '27-2022.00', '27-2023.00', '27-3022.00', '27-3031.00', '27-3041.00', '27-3042.00', '27-3043.04', '27-3043.05', '27-3091.00', '27-4011.00', '27-4012.00', '27-4014.00', '27-4021.00', '27-4031.00', '27-4032.00', '41-1011.00', '41-1012.00', '41-2011.00', '41-2031.00', '41-3011.00', '41-3021.00', '41-3031.02', '41-3099.00', '41-4011.00', '41-4012.00', '41-9011.00', '41-9022.00', '41-9031.00', '41-9099.00']\n"
     ]
    }
   ],
   "source": [
    "intersection = find_intersection()\n",
    "print(\"Number of ONET codes available in all years: {}\".format(len(intersection)))\n",
    "print(intersection)\n",
    "# in intersection: 15-1199.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'13-1081.01', '27-2041.04', '27-2012.04', '41-9091.00', '27-4013.00', '27-1012.00', '41-3031.03', '15-2021.00', '13-1032.00', '27-2032.00', '13-1021.00', '41-9012.00', '13-1011.00', '41-2012.00', '13-2021.01', '13-1131.00', '13-1041.02', '27-2042.01', '27-2041.01', '41-4011.07', '41-2021.00', '27-2011.00', '27-2012.05', '13-2082.00', '15-1199.05', '27-2012.02', '41-9021.00', '27-2099.00', '13-1031.02', '27-2021.00', '27-2042.02', '13-1041.06', '13-2071.01', '41-3031.01', '41-3041.00', '13-1199.03', '27-3011.00', '27-3012.00', '15-1121.01', '41-9041.00', '13-1199.05', '27-1023.00', '15-2011.00', '41-3099.01', '13-2061.00', '15-2041.02', '13-2021.02', '41-2022.00', '13-1075.00', '27-1027.00', '27-3021.00', '13-1041.03', '13-1041.04', '13-1041.01', '13-2031.00', '27-2031.00'}\n"
     ]
    }
   ],
   "source": [
    "union = find_union()\n",
    "print(set(union) - set(intersection))\n",
    "# not in intersection: 13-2031.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 1: ONET Codes 15-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '15'\n",
    "!mkdir '15'\n",
    "\n",
    "K = range(2,30)\n",
    "onet_parent = '15'\n",
    "title = 'Trending analysis for the ONET Code 15-*'\n",
    "onet_model = onet_parent+'/'+onet_parent+'_model.pkl'\n",
    "# language_model = 'all-MiniLM-L6-v2'\n",
    "language_model = 'all-mpnet-base-v2'\n",
    "onet_k_value = onet_parent+'/'+onet_parent+'_k_value.png'\n",
    "onet_cluster_data = onet_parent+'/'+onet_parent+'_cluster_data'\n",
    "onet_bar_chart = onet_parent+'/'+onet_parent+'_bar_charts.html'\n",
    "onet_line_chart = onet_parent+'/'+onet_parent+'_line_chart.html'\n",
    "onet_bubble_chart = onet_parent+'/'+onet_parent+'_bubble_chart.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of skills\n",
    "skills = []\n",
    "skills_per_year = []\n",
    "for df in dfs:\n",
    "    skills.extend(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "    skills_per_year.append(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "skills = list(set(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Embeddings\n",
    "model = SentenceTransformer(language_model)\n",
    "skills_embeddings = model.encode(skills)\n",
    "skills_per_year_embeddings = []\n",
    "for item in skills_per_year:\n",
    "    skills_per_year_embeddings.append(model.encode(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal K value based on silhouette score is 24 with a score of 0.04645084962248802\n"
     ]
    }
   ],
   "source": [
    "# using elbow method to figure out ideal number of clusters\n",
    "# distortions = []\n",
    "score=0\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, init='k-means++')\n",
    "    model.fit_predict(skills_embeddings)\n",
    "#     distortions.append(model.inertia_)\n",
    "    new_score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "    if new_score>score:\n",
    "        number_of_clusters = k\n",
    "        score=new_score\n",
    "\n",
    "print(\"Ideal K value based on silhouette score is {} with a score of {}\".format(number_of_clusters, score))\n",
    "# kn = KneeLocator(list(K), distortions, S=1.0, curve='convex', direction='decreasing')\n",
    "# number_of_clusters = kn.knee\n",
    "# print(\"Ideal K value based on elbow method = {}\".format(number_of_clusters))\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.vlines(number_of_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.savefig(onet_k_value, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.041\n"
     ]
    }
   ],
   "source": [
    "model = KMeans(n_clusters=number_of_clusters)\n",
    "cluster_assignment = model.fit_predict(skills_embeddings)\n",
    "\n",
    "clustered_skills = {}\n",
    "for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_skills:\n",
    "        clustered_skills[cluster_id] = []\n",
    "    clustered_skills[cluster_id].append(skills[skill_id])\n",
    "\n",
    "score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "print('Silhouette Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = \"{'silhouette_score':'\"+str(score)+\"',\"\n",
    "for key in sorted(clustered_skills):\n",
    "    cluster_data=cluster_data+str(key)+\":\"+str(clustered_skills[key])+\",\"\n",
    "cluster_data=cluster_data[:-1]+\"}\"\n",
    "with open(onet_cluster_data+\".json\", 'w') as f:\n",
    "    f.write(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(onet_model, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(onet_model, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for year 2010\n",
      "Predicting for year 2011\n",
      "Predicting for year 2012\n",
      "Predicting for year 2013\n",
      "Predicting for year 2014\n",
      "Predicting for year 2015\n",
      "Predicting for year 2016\n",
      "Predicting for year 2017\n",
      "Predicting for year 2018\n",
      "Predicting for year 2019\n",
      "Predicting for year 2020\n",
      "Predicting for year 2021\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['year', 'skills', 'cluster', \n",
    "                           'cluster_centers', 'cluster_centers_x', 'cluster_centers_y', \n",
    "                           'cluster_skill_count'], dtype=object)\n",
    "\n",
    "for i in range(0, len(skills_per_year_embeddings)):\n",
    "    year=years[i]\n",
    "    print(\"Predicting for year {}\".format(year))\n",
    "    cluster_assignment = model.predict(skills_per_year_embeddings[i])\n",
    "\n",
    "    clustered_skills = {}\n",
    "    for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "        if cluster_id not in clustered_skills:\n",
    "            clustered_skills[cluster_id] = []\n",
    "        clustered_skills[cluster_id].append(skills_per_year[i][skill_id])\n",
    "    \n",
    "    for key in sorted(clustered_skills):\n",
    "        count = 0\n",
    "        for skill in clustered_skills[key]:\n",
    "            count += yearly_dfs[year].loc[yearly_dfs[year]['skill'] == skill, 'count'].sum()\n",
    "        row = {'year': year, 'skills':', '.join(clustered_skills[key]), 'cluster':key, \n",
    "               'cluster_centers': key+1,'cluster_centers_x': model.cluster_centers_[:,0],\n",
    "               'cluster_centers_y': model.cluster_centers_[:,1], 'cluster_skill_count':count}\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "df.year = df.year.astype(int)\n",
    "df.cluster = df.cluster.astype(int)\n",
    "df.cluster_skill_count = df.cluster_skill_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='cluster_skill_count',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\"},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='cluster_skill_count', title='2010', labels=labels),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='cluster_skill_count', title='2011', labels=labels),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='cluster_skill_count', title='2012', labels=labels),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='cluster_skill_count', title='2013', labels=labels),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='cluster_skill_count', title='2014', labels=labels),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='cluster_skill_count', title='2015', labels=labels),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='cluster_skill_count', title='2016', labels=labels),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='cluster_skill_count', title='2017', labels=labels),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='cluster_skill_count', title='2018', labels=labels),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='cluster_skill_count', title='2019', labels=labels),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='cluster_skill_count', title='2020', labels=labels),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='cluster_skill_count', title='2021', labels=labels)\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "\n",
    "fig = px.line(df, x='year', y='cluster_skill_count', color='cluster', labels=labels)\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(onet_line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 2: ONET Codes 13-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '13'\n",
    "!mkdir '13'\n",
    "\n",
    "K = range(2,30)\n",
    "onet_parent = '13'\n",
    "title = 'Trending analysis for the ONET Code 13-*'\n",
    "onet_model = onet_parent+'/'+onet_parent+'_model.pkl'\n",
    "# language_model = 'all-MiniLM-L6-v2'\n",
    "language_model = 'all-mpnet-base-v2'\n",
    "onet_k_value = onet_parent+'/'+onet_parent+'_k_value.png'\n",
    "onet_cluster_data = onet_parent+'/'+onet_parent+'_cluster_data'\n",
    "onet_bar_chart = onet_parent+'/'+onet_parent+'_bar_charts.html'\n",
    "onet_line_chart = onet_parent+'/'+onet_parent+'_line_chart.html'\n",
    "onet_bubble_chart = onet_parent+'/'+onet_parent+'_bubble_chart.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of skills\n",
    "skills = []\n",
    "skills_per_year = []\n",
    "for df in dfs:\n",
    "    skills.extend(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "    skills_per_year.append(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "skills = list(set(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Embeddings\n",
    "model = SentenceTransformer(language_model)\n",
    "skills_embeddings = model.encode(skills)\n",
    "skills_per_year_embeddings = []\n",
    "for item in skills_per_year:\n",
    "    skills_per_year_embeddings.append(model.encode(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal K value based on silhouette score is 24 with a score of 0.04817359894514084\n"
     ]
    }
   ],
   "source": [
    "# using elbow method to figure out ideal number of clusters\n",
    "# distortions = []\n",
    "score=0\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, init='k-means++')\n",
    "    model.fit_predict(skills_embeddings)\n",
    "#     distortions.append(model.inertia_)\n",
    "    new_score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "    if new_score>score:\n",
    "        number_of_clusters = k\n",
    "        score=new_score\n",
    "\n",
    "print(\"Ideal K value based on silhouette score is {} with a score of {}\".format(number_of_clusters, score))\n",
    "# kn = KneeLocator(list(K), distortions, S=1.0, curve='convex', direction='decreasing')\n",
    "# number_of_clusters = kn.knee\n",
    "# print(\"Ideal K value based on elbow method = {}\".format(number_of_clusters))\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.vlines(number_of_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.savefig(onet_k_value, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.046\n"
     ]
    }
   ],
   "source": [
    "model = KMeans(n_clusters=number_of_clusters)\n",
    "cluster_assignment = model.fit_predict(skills_embeddings)\n",
    "\n",
    "clustered_skills = {}\n",
    "for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_skills:\n",
    "        clustered_skills[cluster_id] = []\n",
    "    clustered_skills[cluster_id].append(skills[skill_id])\n",
    "\n",
    "score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "print('Silhouette Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = \"{'silhouette_score':'\"+str(score)+\"',\"\n",
    "for key in sorted(clustered_skills):\n",
    "    cluster_data=cluster_data+str(key)+\":\"+str(clustered_skills[key])+\",\"\n",
    "cluster_data=cluster_data[:-1]+\"}\"\n",
    "with open(onet_cluster_data+\".json\", 'w') as f:\n",
    "    f.write(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(onet_model, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(onet_model, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for year 2010\n",
      "Predicting for year 2011\n",
      "Predicting for year 2012\n",
      "Predicting for year 2013\n",
      "Predicting for year 2014\n",
      "Predicting for year 2015\n",
      "Predicting for year 2016\n",
      "Predicting for year 2017\n",
      "Predicting for year 2018\n",
      "Predicting for year 2019\n",
      "Predicting for year 2020\n",
      "Predicting for year 2021\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['year', 'skills', 'cluster', \n",
    "                           'cluster_centers', 'cluster_centers_x', 'cluster_centers_y', \n",
    "                           'cluster_skill_count'], dtype=object)\n",
    "\n",
    "for i in range(0, len(skills_per_year_embeddings)):\n",
    "    year=years[i]\n",
    "    print(\"Predicting for year {}\".format(year))\n",
    "    cluster_assignment = model.predict(skills_per_year_embeddings[i])\n",
    "\n",
    "    clustered_skills = {}\n",
    "    for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "        if cluster_id not in clustered_skills:\n",
    "            clustered_skills[cluster_id] = []\n",
    "        clustered_skills[cluster_id].append(skills_per_year[i][skill_id])\n",
    "    \n",
    "    for key in sorted(clustered_skills):\n",
    "        count = 0\n",
    "        for skill in clustered_skills[key]:\n",
    "            count += yearly_dfs[year].loc[yearly_dfs[year]['skill'] == skill, 'count'].sum()\n",
    "        row = {'year': year, 'skills':', '.join(clustered_skills[key]), 'cluster':key, \n",
    "               'cluster_centers': key+1,'cluster_centers_x': model.cluster_centers_[:,0],\n",
    "               'cluster_centers_y': model.cluster_centers_[:,1], 'cluster_skill_count':count}\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "df.year = df.year.astype(int)\n",
    "df.cluster = df.cluster.astype(int)\n",
    "df.cluster_skill_count = df.cluster_skill_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='cluster_skill_count',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\"},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='cluster_skill_count', title='2010', labels=labels),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='cluster_skill_count', title='2011', labels=labels),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='cluster_skill_count', title='2012', labels=labels),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='cluster_skill_count', title='2013', labels=labels),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='cluster_skill_count', title='2014', labels=labels),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='cluster_skill_count', title='2015', labels=labels),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='cluster_skill_count', title='2016', labels=labels),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='cluster_skill_count', title='2017', labels=labels),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='cluster_skill_count', title='2018', labels=labels),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='cluster_skill_count', title='2019', labels=labels),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='cluster_skill_count', title='2020', labels=labels),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='cluster_skill_count', title='2021', labels=labels)\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "\n",
    "fig = px.line(df, x='year', y='cluster_skill_count', color='cluster', labels=labels)\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(onet_line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 3: ONET Codes 41-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '41'\n",
    "!mkdir '41'\n",
    "\n",
    "K = range(2,30)\n",
    "onet_parent = '41'\n",
    "title = 'Trending analysis for the ONET Code 41-*'\n",
    "onet_model = onet_parent+'/'+onet_parent+'_model.pkl'\n",
    "# language_model = 'all-MiniLM-L6-v2'\n",
    "language_model = 'all-mpnet-base-v2'\n",
    "onet_k_value = onet_parent+'/'+onet_parent+'_k_value.png'\n",
    "onet_cluster_data = onet_parent+'/'+onet_parent+'_cluster_data'\n",
    "onet_bar_chart = onet_parent+'/'+onet_parent+'_bar_charts.html'\n",
    "onet_line_chart = onet_parent+'/'+onet_parent+'_line_chart.html'\n",
    "onet_bubble_chart = onet_parent+'/'+onet_parent+'_bubble_chart.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of skills\n",
    "skills = []\n",
    "skills_per_year = []\n",
    "for df in dfs:\n",
    "    skills.extend(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "    skills_per_year.append(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "skills = list(set(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Embeddings\n",
    "model = SentenceTransformer(language_model)\n",
    "skills_embeddings = model.encode(skills)\n",
    "skills_per_year_embeddings = []\n",
    "for item in skills_per_year:\n",
    "    skills_per_year_embeddings.append(model.encode(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal K value based on silhouette score is 22 with a score of 0.04604271799325943\n"
     ]
    }
   ],
   "source": [
    "# using elbow method to figure out ideal number of clusters\n",
    "# distortions = []\n",
    "score=0\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, init='k-means++')\n",
    "    model.fit_predict(skills_embeddings)\n",
    "#     distortions.append(model.inertia_)\n",
    "    new_score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "    if new_score>score:\n",
    "        number_of_clusters = k\n",
    "        score=new_score\n",
    "\n",
    "print(\"Ideal K value based on silhouette score is {} with a score of {}\".format(number_of_clusters, score))\n",
    "# kn = KneeLocator(list(K), distortions, S=1.0, curve='convex', direction='decreasing')\n",
    "# number_of_clusters = kn.knee\n",
    "# print(\"Ideal K value based on elbow method = {}\".format(number_of_clusters))\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.vlines(number_of_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.savefig(onet_k_value, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.041\n"
     ]
    }
   ],
   "source": [
    "model = KMeans(n_clusters=number_of_clusters)\n",
    "cluster_assignment = model.fit_predict(skills_embeddings)\n",
    "\n",
    "clustered_skills = {}\n",
    "for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_skills:\n",
    "        clustered_skills[cluster_id] = []\n",
    "    clustered_skills[cluster_id].append(skills[skill_id])\n",
    "\n",
    "score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "print('Silhouette Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = \"{'silhouette_score':'\"+str(score)+\"',\"\n",
    "for key in sorted(clustered_skills):\n",
    "    cluster_data=cluster_data+str(key)+\":\"+str(clustered_skills[key])+\",\"\n",
    "cluster_data=cluster_data[:-1]+\"}\"\n",
    "with open(onet_cluster_data+\".json\", 'w') as f:\n",
    "    f.write(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(onet_model, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(onet_model, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for year 2010\n",
      "Predicting for year 2011\n",
      "Predicting for year 2012\n",
      "Predicting for year 2013\n",
      "Predicting for year 2014\n",
      "Predicting for year 2015\n",
      "Predicting for year 2016\n",
      "Predicting for year 2017\n",
      "Predicting for year 2018\n",
      "Predicting for year 2019\n",
      "Predicting for year 2020\n",
      "Predicting for year 2021\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['year', 'skills', 'cluster', \n",
    "                           'cluster_centers', 'cluster_centers_x', 'cluster_centers_y', \n",
    "                           'cluster_skill_count'], dtype=object)\n",
    "\n",
    "for i in range(0, len(skills_per_year_embeddings)):\n",
    "    year=years[i]\n",
    "    print(\"Predicting for year {}\".format(year))\n",
    "    cluster_assignment = model.predict(skills_per_year_embeddings[i])\n",
    "\n",
    "    clustered_skills = {}\n",
    "    for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "        if cluster_id not in clustered_skills:\n",
    "            clustered_skills[cluster_id] = []\n",
    "        clustered_skills[cluster_id].append(skills_per_year[i][skill_id])\n",
    "    \n",
    "    for key in sorted(clustered_skills):\n",
    "        count = 0\n",
    "        for skill in clustered_skills[key]:\n",
    "            count += yearly_dfs[year].loc[yearly_dfs[year]['skill'] == skill, 'count'].sum()\n",
    "        row = {'year': year, 'skills':', '.join(clustered_skills[key]), 'cluster':key, \n",
    "               'cluster_centers': key+1,'cluster_centers_x': model.cluster_centers_[:,0],\n",
    "               'cluster_centers_y': model.cluster_centers_[:,1], 'cluster_skill_count':count}\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "df.year = df.year.astype(int)\n",
    "df.cluster = df.cluster.astype(int)\n",
    "df.cluster_skill_count = df.cluster_skill_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='cluster_skill_count',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\"},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='cluster_skill_count', title='2010', labels=labels),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='cluster_skill_count', title='2011', labels=labels),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='cluster_skill_count', title='2012', labels=labels),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='cluster_skill_count', title='2013', labels=labels),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='cluster_skill_count', title='2014', labels=labels),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='cluster_skill_count', title='2015', labels=labels),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='cluster_skill_count', title='2016', labels=labels),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='cluster_skill_count', title='2017', labels=labels),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='cluster_skill_count', title='2018', labels=labels),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='cluster_skill_count', title='2019', labels=labels),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='cluster_skill_count', title='2020', labels=labels),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='cluster_skill_count', title='2021', labels=labels)\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "\n",
    "fig = px.line(df, x='year', y='cluster_skill_count', color='cluster', labels=labels)\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(onet_line_chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 4: ONET Codes 27-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf '27'\n",
    "!mkdir '27'\n",
    "\n",
    "K = range(2,30)\n",
    "onet_parent = '27'\n",
    "title = 'Trending analysis for the ONET Code 27-*'\n",
    "onet_model = onet_parent+'/'+onet_parent+'_model.pkl'\n",
    "# language_model = 'all-MiniLM-L6-v2'\n",
    "language_model = 'all-mpnet-base-v2'\n",
    "onet_k_value = onet_parent+'/'+onet_parent+'_k_value.png'\n",
    "onet_cluster_data = onet_parent+'/'+onet_parent+'_cluster_data'\n",
    "onet_bar_chart = onet_parent+'/'+onet_parent+'_bar_charts.html'\n",
    "onet_line_chart = onet_parent+'/'+onet_parent+'_line_chart.html'\n",
    "onet_bubble_chart = onet_parent+'/'+onet_parent+'_bubble_chart.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of skills\n",
    "skills = []\n",
    "skills_per_year = []\n",
    "for df in dfs:\n",
    "    skills.extend(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "    skills_per_year.append(df[df['onet_parent'] == onet_parent]['skill'].unique().tolist())\n",
    "skills = list(set(skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Embeddings\n",
    "model = SentenceTransformer(language_model)\n",
    "skills_embeddings = model.encode(skills)\n",
    "skills_per_year_embeddings = []\n",
    "for item in skills_per_year:\n",
    "    skills_per_year_embeddings.append(model.encode(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal K value based on silhouette score is 29 with a score of 0.046428415924310684\n"
     ]
    }
   ],
   "source": [
    "# using elbow method to figure out ideal number of clusters\n",
    "# distortions = []\n",
    "score=0\n",
    "for k in K:\n",
    "    model = KMeans(n_clusters=k, init='k-means++')\n",
    "    model.fit_predict(skills_embeddings)\n",
    "#     distortions.append(model.inertia_)\n",
    "    new_score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "    if new_score>score:\n",
    "        number_of_clusters = k\n",
    "        score=new_score\n",
    "\n",
    "print(\"Ideal K value based on silhouette score is {} with a score of {}\".format(number_of_clusters, score))\n",
    "# kn = KneeLocator(list(K), distortions, S=1.0, curve='convex', direction='decreasing')\n",
    "# number_of_clusters = kn.knee\n",
    "# print(\"Ideal K value based on elbow method = {}\".format(number_of_clusters))\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('Distortion')\n",
    "# plt.title('The Elbow Method showing the optimal k')\n",
    "# plt.plot(K, distortions, 'bx-')\n",
    "# plt.vlines(number_of_clusters, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n",
    "# plt.savefig(onet_k_value, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.046\n"
     ]
    }
   ],
   "source": [
    "model = KMeans(n_clusters=number_of_clusters)\n",
    "cluster_assignment = model.fit_predict(skills_embeddings)\n",
    "\n",
    "clustered_skills = {}\n",
    "for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "    if cluster_id not in clustered_skills:\n",
    "        clustered_skills[cluster_id] = []\n",
    "    clustered_skills[cluster_id].append(skills[skill_id])\n",
    "\n",
    "score = silhouette_score(skills_embeddings, model.labels_, metric='euclidean')\n",
    "print('Silhouette Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = \"{'silhouette_score':'\"+str(score)+\"',\"\n",
    "for key in sorted(clustered_skills):\n",
    "    cluster_data=cluster_data+str(key)+\":\"+str(clustered_skills[key])+\",\"\n",
    "cluster_data=cluster_data[:-1]+\"}\"\n",
    "with open(onet_cluster_data+\".json\", 'w') as f:\n",
    "    f.write(cluster_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(onet_model, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(onet_model, \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for year 2010\n",
      "Predicting for year 2011\n",
      "Predicting for year 2012\n",
      "Predicting for year 2013\n",
      "Predicting for year 2014\n",
      "Predicting for year 2015\n",
      "Predicting for year 2016\n",
      "Predicting for year 2017\n",
      "Predicting for year 2018\n",
      "Predicting for year 2019\n",
      "Predicting for year 2020\n",
      "Predicting for year 2021\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['year', 'skills', 'cluster', \n",
    "                           'cluster_centers', 'cluster_centers_x', 'cluster_centers_y', \n",
    "                           'cluster_skill_count'], dtype=object)\n",
    "\n",
    "for i in range(0, len(skills_per_year_embeddings)):\n",
    "    year=years[i]\n",
    "    print(\"Predicting for year {}\".format(year))\n",
    "    cluster_assignment = model.predict(skills_per_year_embeddings[i])\n",
    "\n",
    "    clustered_skills = {}\n",
    "    for skill_id, cluster_id in enumerate(cluster_assignment):\n",
    "        if cluster_id not in clustered_skills:\n",
    "            clustered_skills[cluster_id] = []\n",
    "        clustered_skills[cluster_id].append(skills_per_year[i][skill_id])\n",
    "    \n",
    "    for key in sorted(clustered_skills):\n",
    "        count = 0\n",
    "        for skill in clustered_skills[key]:\n",
    "            count += yearly_dfs[year].loc[yearly_dfs[year]['skill'] == skill, 'count'].sum()\n",
    "        row = {'year': year, 'skills':', '.join(clustered_skills[key]), 'cluster':key, \n",
    "               'cluster_centers': key+1,'cluster_centers_x': model.cluster_centers_[:,0],\n",
    "               'cluster_centers_y': model.cluster_centers_[:,1], 'cluster_skill_count':count}\n",
    "        df = df.append(row, ignore_index=True)\n",
    "        \n",
    "df.year = df.year.astype(int)\n",
    "df.cluster = df.cluster.astype(int)\n",
    "df.cluster_skill_count = df.cluster_skill_count.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(onet_cluster_data+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='cluster_centers',\n",
    "    y='cluster_centers',\n",
    "    animation_frame='year',\n",
    "    animation_group='cluster',\n",
    "    size='cluster_skill_count',\n",
    "    color='cluster',\n",
    "    hover_name=\"cluster\",\n",
    "    hover_data={ 'year':False, 'cluster_centers':False, 'cluster':False, 'skills': True},\n",
    "    labels={'cluster_skill_count': 'Count', 'skills': 'Skills', 'cluster_centers': \"Cluster\"},\n",
    "    log_x=False,\n",
    "    range_x=[0, number_of_clusters+1],\n",
    "    range_y=[0, number_of_clusters+1],\n",
    "    title=title\n",
    ")\n",
    "fig.update(layout_coloraxis_showscale=True)\n",
    "# fig.show()\n",
    "fig.write_html(onet_bubble_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "figures = [\n",
    "    px.bar(df[df['year']==2010], x='cluster', y='cluster_skill_count', title='2010', labels=labels),\n",
    "    px.bar(df[df['year']==2011], x='cluster', y='cluster_skill_count', title='2011', labels=labels),\n",
    "    px.bar(df[df['year']==2012], x='cluster', y='cluster_skill_count', title='2012', labels=labels),\n",
    "    px.bar(df[df['year']==2013], x='cluster', y='cluster_skill_count', title='2013', labels=labels),\n",
    "    px.bar(df[df['year']==2014], x='cluster', y='cluster_skill_count', title='2014', labels=labels),\n",
    "    px.bar(df[df['year']==2015], x='cluster', y='cluster_skill_count', title='2015', labels=labels),\n",
    "    px.bar(df[df['year']==2016], x='cluster', y='cluster_skill_count', title='2016', labels=labels),\n",
    "    px.bar(df[df['year']==2017], x='cluster', y='cluster_skill_count', title='2017', labels=labels),\n",
    "    px.bar(df[df['year']==2018], x='cluster', y='cluster_skill_count', title='2018', labels=labels),\n",
    "    px.bar(df[df['year']==2019], x='cluster', y='cluster_skill_count', title='2019', labels=labels),\n",
    "    px.bar(df[df['year']==2020], x='cluster', y='cluster_skill_count', title='2020', labels=labels),\n",
    "    px.bar(df[df['year']==2021], x='cluster', y='cluster_skill_count', title='2021', labels=labels)\n",
    "]\n",
    "\n",
    "fig = make_subplots(rows=6, cols=2, subplot_titles=range(2010, 2022)) \n",
    "        \n",
    "for i, figure in enumerate(figures):\n",
    "    if i==0:\n",
    "        r, c = 1, 1\n",
    "    elif i==1:\n",
    "        r, c = 1, 2\n",
    "    elif i==2:\n",
    "        r, c = 2, 1\n",
    "    elif i==3:\n",
    "        r, c = 2, 2\n",
    "    elif i==4:\n",
    "        r, c = 3, 1\n",
    "    elif i==5:\n",
    "        r, c = 3, 2\n",
    "    elif i==6:\n",
    "        r, c = 4, 1\n",
    "    elif i==7:\n",
    "        r, c = 4, 2\n",
    "    elif i==8:\n",
    "        r, c = 5, 1\n",
    "    elif i==9:\n",
    "        r, c = 5, 2\n",
    "    elif i==10:\n",
    "        r, c = 6, 1\n",
    "    elif i==11:\n",
    "        r, c = 6, 2\n",
    "    for trace in range(len(figure[\"data\"])):\n",
    "        fig.append_trace(figure[\"data\"][trace], row=r, col=c)\n",
    "\n",
    "fig.update_layout(height=1500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "# fig.show()\n",
    "fig.write_html(onet_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels={'cluster_skill_count': 'Count', 'cluster': \"Cluster\"}\n",
    "\n",
    "fig = px.line(df, x='year', y='cluster_skill_count', color='cluster', labels=labels)\n",
    "\n",
    "fig.update_layout(height=500, width=1500, title_text=title)\n",
    "fig.update_xaxes(tickmode='linear')\n",
    "fig.write_html(onet_line_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
